{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graph mode, no values will be returned immediately but we have to creat a session for our code to return values. Only the name, shape and type is stored first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding two tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Add:0' shape=(3,) dtype=int32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(value = [2,3,4], dtype = tf.int32)\n",
    "b = tf.constant(value = [3,4,5], dtype = tf.int32)\n",
    "\n",
    "c = tf.add(x = a, y = b)\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see it is only giving us shape, dtype and type of our object. To get concrete values, we got to create session and run it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the graph\n",
    "\n",
    "So, lets try and do that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 7 9]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run(fetches = c)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametrising the graph. \n",
    "\n",
    "What is the values of a and b keeps changing. To deal with that we will need to use placeholders which need not be initialised with values and only requires shape and dtype. So, lets try and work it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 7 9]\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(dtype = tf.int32, shape =[None])\n",
    "b = tf.placeholder(dtype = tf.int32 , shape = [None])\n",
    "\n",
    "c = tf.add(x = a, y = b)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(fetches = c, feed_dict = {\n",
    "        a : [2,3,4,],\n",
    "        b : [3,4,5,]\n",
    "    })\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "Let us repeat the same thing we have done with our eager notebook. Implementing the simple linear regression with toy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:Tensor(\"Const_2:0\", shape=(10,), dtype=float32)\n",
      "Y:Tensor(\"add_5:0\", shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X = tf.constant(value = [1,2,3,4,5,6,7,8,9,10], dtype = tf.float32)\n",
    "Y = 2*X + 10\n",
    "\n",
    "print(\"X:{}\".format(X))\n",
    "print(\"Y:{}\".format(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "\n",
    "We will initialise the weights and define a loss fucntion so as to evaluate our linear model. Also, we are going to define the tf varaibles for first time which happen to be mutable unlike our constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vikas\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(name_or_scope = \"training\", reuse = tf.AUTO_REUSE):\n",
    "    w0 = tf.get_variable(name = \"w0\", initializer = tf.constant(value = 0.0, dtype = tf.float32))\n",
    "    w1 = tf.get_variable(name = \"w1\", initializer = tf.constant(value= 0.0, dtype = tf.float32))\n",
    "    \n",
    "Y_hat = w0*X + w1\n",
    "\n",
    "loss_mse = tf.reduce_mean(input_tensor = (Y_hat-Y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer \n",
    "\n",
    "Tensorflow gives us access to many types of pre-built optimizers which we can use directly. In this case we are using the gradient descent optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = tf.placeholder(dtype= tf.float32, shape =None)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = LEARNING_RATE).minimize(loss = loss_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP :0, MSE :167.6111297607422\n",
      "STEP :100, MSE :3.5321757793426514\n",
      "STEP :200, MSE :0.6537718176841736\n",
      "STEP :300, MSE :0.12100745737552643\n",
      "STEP :400, MSE :0.022397063672542572\n",
      "STEP :500, MSE :0.004145540297031403\n",
      "STEP :600, MSE :0.0007674093940295279\n",
      "STEP :700, MSE :0.00014202017337083817\n",
      "STEP :800, MSE :2.628635775181465e-05\n",
      "STEP :900, MSE :4.86889211970265e-06\n",
      "STEP: 1000 MSE: 9.178326081382693e-07\n",
      "w0:2.0003\n",
      "w1:9.9979\n"
     ]
    }
   ],
   "source": [
    "STEPS = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) #initialise variables\n",
    "    \n",
    "    for step in range(STEPS):\n",
    "        #Calculate gradients and update weights\n",
    "        sess.run(fetches = optimizer, feed_dict = {LEARNING_RATE:0.02})\n",
    "        \n",
    "        #Print mse periodicly\n",
    "        if step%100 == 0:\n",
    "            print(\"STEP :{}, MSE :{}\".format(step, sess.run(fetches = loss_mse)))\n",
    "            \n",
    "            \n",
    "    #print final weights and mse\n",
    "    print(\"STEP: {} MSE: {}\".format(STEPS, sess.run(loss_mse)))\n",
    "    print(\"w0:{}\".format(round(float(sess.run(w0)), 4)))\n",
    "    print(\"w1:{}\".format(round(float(sess.run(w1)), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
